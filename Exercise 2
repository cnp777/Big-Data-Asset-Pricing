---
title: "AP_Exercise2_final"
output:
  pdf_document: default
  html_document: default
date: "2023-03-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(RSQLite)
library(lubridate)
library(scales)
library(frenchdata)
library(RPostgres)
library(tidyverse)
library(dbplyr)
library(reshape2)

start_date <- ymd("1926-01-01")
end_date <- ymd("2021-12-31")

# To establish the connection to WRDS, we use the function dbConnect(), and fill in our personal user and password.
wrds <- dbConnect(
  Postgres(),
  host = "wrds-pgdata.wharton.upenn.edu",
  dbname = "wrds",
  port = 9737,
  sslmode = "require",
  user = "cet_fi",
  password = "0602cbsClara!"
)

```



The code in this exercise is inspired by Tidy Finance with R: https://www.tidy-finance.org/replicating-fama-and-french-factors.html 


## Problem 1

In this problem we wish to compute the book-to-market ratio (BE/ME) that underlies the Fama-French HML factor. We will use US annual accounting data from Compustat and monthly price data from CRSP. 


We start by creating the file where we will store and retrieve data from. 

```{r}
database_cet <- dbConnect(
  SQLite(),
  "C:/Users/cet.fi/OneDrive - CBS - Copenhagen Business School/Big Data Asset Pricing/database_cet.sqlite", 
  extended_types = TRUE  # set equal to true to enable date types (otherwise fx date columns are stored and retrieved as integers)
)
#file.exists("database_cet.sqlite") # this should be true - otherwise check path
```

We start by downloading the Fama-French data 
```{r}
ff_monthly_raw <- download_french_data("Fama/French 3 Factors")
ff_monthly <- ff_monthly_raw$subsets$data[[1]] %>% 
  transmute(
    month = floor_date(ymd(str_c(date, "01")), "month"),
    rf = as.numeric(RF) / 100,
    mkt_excess = as.numeric(`Mkt-RF`) / 100,
    smb = as.numeric(SMB) / 100,
    hml = as.numeric(HML) / 100
  ) %>% 
  filter(month >= start_date & month <= end_date)
```

We download the US stock data from CRSP. As we will later merge with compustat, we also add the linking table, and further, as we work with monthly data, we create a new 'month' column. 

```{r}
msf_crsp = tbl(wrds, in_schema("crsp", "msf")) # CRSP monthly security file
msenames_crsp = tbl(wrds, in_schema("crsp", "msenames")) # identifying information

# Merge the two
crsp_monthly = msf_crsp %>% 
  filter(date >= start_date & date <= end_date) %>% #  keep only data in the time windows of interest
  inner_join( # merge CRSP monthly security file with the identifying information table
    msenames_crsp %>% 
      filter(shrcd %in% c(10, 11)) %>%  # keep only US-listed stocks (identified via share codes 'shrcd' 10 and 11)
      select(permno, exchcd, siccd, namedt, nameendt),
    by = c("permno") # merge the two data sets by security identifier 'permno'
  ) %>% # after merging the two data sets apply filters to 
  filter(date >= namedt & date <= nameendt) %>%  # permno-specific start dates: namedt and end dates: nameendt
  mutate(month = floor_date(date, "month")) %>%  # add month variable to the data. extract from date column. 
# add  explicit exchange names
  mutate(exchange = case_when(
    exchcd %in% c(1, 31) ~ "NYSE",
    exchcd %in% c(2, 32) ~ "AMEX",
    exchcd %in% c(3, 33) ~ "NASDAQ",
    TRUE ~ "Other"
  )) 
```

For most observations the 'ret' column indicates the monthly return, except for the stocks which delisted from an exchange within a given month. In this case the last traded price is not necessarily an indicator of the monthly return. CRSP have a monthly delistings file to deal with this issue. We download this and merge with the crsp data set we already have.

```{r}
msedelist_crsp <- tbl(wrds, in_schema("crsp", "msedelist")) # table of the delisting information
msedelist_crsp = msedelist_crsp %>% 
  select(permno, dlstdt, dlret, dlstcd) %>%       # identifier, date, return, delisting reason
      mutate(month = floor_date(dlstdt, "month")) # as we work with monthly returns

# merge with delisting codes and returns
crsp_monthly = crsp_monthly %>% 
  left_join(msedelist_crsp, by = c("permno", "month")) %>% 
  select(
    permno,  # Security identifier
    date,    # Date of the observation
    month,   # Month of the observation
    ret,     # Return
    shrout,  # Shares outstanding (in thousands)
    altprc,  # Last traded price in a month
    exchcd,  # Exchange code
    siccd,   # Industry code
    dlret,   # Delisting return
    dlstcd,  # Delisting code
    exchange # Exchange name
  ) %>% 
   collect() %>% 
  mutate(
    month = ymd(month),
    shrout = shrout * 1000 # CRSP reports shares outstanding in thousands - change to actual number
  )
```

We quickly find that some delisting returns are missing (column 'dlret'). This is the case as CRSP are not always able to determine a post-delisting value of the stock. To handle these we apply the methodology of Shumway (1997), who examines delisting bias in CRSP data. We make use of the reason for the delisting (column 'dlstcd'), and set the delisting returns to $-30\%$ when the delisting happened for performance related reasons (when dlstcd is equal to 500 or between 520 and 584, see Shumway (1997) Table I).

```{r}
crsp_monthly = crsp_monthly %>% 
  mutate(ret_adj = case_when(
    is.na(dlstcd) ~ ret,
    !is.na(dlstcd) & !is.na(dlret) ~ dlret,
    dlstcd == 500 | (dlstcd >= 520 & dlstcd <= 584) ~ -0.30,
    dlstcd == 100 ~ ret, # code 100 means still trading
    TRUE ~ -1            # otherwise set to -100%
  )) %>% 
  select(-c(dlret, dlstcd))
```

We are now ready to calculate the market equity (ME), which is the shares outstanding ('shrout') multiplied by the last traded price of a single share in a given month ('altprc').

```{r}
crsp_monthly = crsp_monthly %>% 
  mutate(
    mktcap = abs(shrout * altprc) / 1000000 , # take absolute value as 'altprc' is negative whenever the last traded price does not exist (fx if a stock splits). 
    # remember to divide by 1000000 as CRSP reports book value of common equity in million dollars
    mktcap = na_if(mktcap, 0)      # if zero market capitalization set to missing value
  ) 
```

We know that we later will need some variables when computing the Fama-French HML factor. More specifically we compute the lagged market capitalization and the excess return, for which we will use the Fama-French risk free rate. 

```{r}
# lagged market capitalization
mktcap_lag = crsp_monthly %>% 
  mutate(month = month %m+% months(1)) %>% 
  select(permno, month, mktcap_lag = mktcap)
# add one month to each observation (above) and then join the information to our monthly CRSP data (below)
crsp_monthly = crsp_monthly %>% 
  left_join(mktcap_lag, by = c("permno", "month"))

# excess return
crsp_monthly = crsp_monthly %>% 
  left_join(ff_monthly %>% select(month, rf),
    by = "month"
  ) %>% 
  mutate(
    ret_excess = ret_adj - rf,
    ret_excess = pmax(ret_excess, -1)
  ) %>% 
  select(-ret_adj, -rf)

```

As a final step in the CRSP data frame, we add the CRSP and Compustat linking table. We follow Bali, Engle, and Murray (2016) chapter 10, in the filters applied to the linking table.

```{r}
ccmxpf_linktable = tbl(wrds,in_schema("crsp", "ccmxpf_linktable"))

ccmxpf_linktable = ccmxpf_linktable %>% 
  filter(linktype %in% c("LU", "LC") &
    linkprim %in% c("P", "C") &
    usedflag == 1) %>% 
  select(permno = lpermno, gvkey, linkdt, linkenddt) %>% 
  collect() %>% 
  # Note that currently active links have no end date (linkenddt), so we just enter the current date via today()
  mutate(linkenddt = replace_na(linkenddt, today()))

# We use these links to create a new table with a mapping between stock identifier, firm identifier, and month. Only include the ones which can be linked: use inner_join
crsp_compustat_link = crsp_monthly %>% 
  inner_join(ccmxpf_linktable, by = "permno") %>% 
  filter(!is.na(gvkey) & (date >= linkdt & date <= linkenddt)) %>% 
  select(permno, gvkey, date)

# We then add the links to the Compustat gvkey to our monthly stock data
crsp_monthly = crsp_monthly %>% 
  left_join(crsp_compustat_link, by = c("permno", "date")) 

# Update the previously prepared monthly CRSP file with the linking information
dbWriteTable(database_cet,
    "crsp_monthly",
    value = crsp_monthly,
    overwrite = TRUE)

# crsp_compustat_link: 1949-07-29 - 2021-12-31	
# crsp_monthly: 1926-01-30 - 2021-12-31

#crsp_monthly %>% arrange(date)
```
The next step is to obtain and clean data from **Compustat**. This is where the accounting data is, i.e. the data which we need to compute the BE value. We follow common filter choices. 

```{r}
funda_db = tbl(wrds, in_schema("comp", "funda"))

compustat = funda_db %>% 
  filter(
    indfmt == "INDL" &   # to get only records in industrial data format
      datafmt == "STD" & 
      # above and below line: the standard format (i.e., consolidated information in standard presentation)
      consol == "C" & 
      datadate >= start_date & datadate <= end_date # only data in our time window
  ) %>% 
  select(
    gvkey, # Firm identifier
    datadate, # Date of the accounting data
    seq, # Stockholders' equity
    ceq, # Total common/ordinary equity
    at, # Total assets
    lt, # Total liabilities
    txditc, # Deferred taxes and investment tax credit
    txdb, # Deferred taxes
    itcb, # Investment tax credit
    pstkrv, # Preferred stock redemption value
    pstkl, # Preferred stock liquidating value
    pstk, # Preferred stock par value
    capx, # Capital investment
    oancf # Operating cash flow
  ) %>% 
  collect()
```

Next, we calculate the book value of preferred stock and equity as defined by the variable definition in Frenchâ€™s data library. (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/variable_definitions.html).   

```{r}
# seq: book value of stockholders equity 
compustat = compustat %>% 
  mutate( # coalesce finds the first non-missing element
    be = coalesce(seq, ceq + pstk, at - lt) + # be as described by Fama and French
      coalesce(txditc, txdb + itcb, 0) -      # add deferred taxes and investment tax credit
      coalesce(pstkrv, pstkl, pstk, 0),       # subtract the book value of preferred stock
    be = if_else(be <= 0, as.numeric(NA), be) # set negative or zero book equity to missing
  )

compustat = compustat %>% 
  mutate(year = year(datadate)) %>% 
  group_by(gvkey, year) %>% 
  filter(datadate == max(datadate)) %>% # keep only the last available information for each (firm, year)-group
  ungroup() 

# Save CompuStat values in our local database
dbWriteTable(database_cet,
    "compustat",
    value = compustat,
    overwrite = TRUE
  )

#compustat %>% arrange(datadate)

```

We add Moody's data 
```{r}
moodys = read.table("DFF_BE_With_Nonindust.txt", header = FALSE, na.strings = "-99.990")

moodys = moodys %>% 
  gather(key="count", value = "bm_be", V4:V79) %>% 
  group_by(V1) %>% 
  mutate(count = parse_number(count),
         count = count -4 ,
         year = 1926 + count,
         sorting_date = ymd(str_c(year, "0701"))) %>% 
  rename(permno = V1) %>% 
  select(permno, bm_be, year, sorting_date) %>% 
  filter(sorting_date < as.Date("1951-07-01") )
```

Merge CRSP with Moody's (for Book Equity before 1951) and with Compustat (for values July 1951 and after)

```{r}
be = compustat %>% 
  mutate(sorting_date = ymd(str_c(year(datadate) + 1, "0701"))) %>% # July year t+1
  select(gvkey, sorting_date, bm_be = be) # %>% 
  #drop_na() # remove all rows with missing values in any of these columns

crsp_monthly_moodys = crsp_monthly %>% 
  mutate(sorting_date = ymd(str_c(year(date), "0701"))) %>% 
  left_join(moodys)

crsp_monthly_moodysbe = crsp_monthly_moodys %>% left_join(be) %>% 
  drop_na(mktcap, exchange, bm_be) # remove all rows with missing values in these columns

crsp_monthly_nona = crsp_monthly %>% drop_na(mktcap, exchange) # 1926-01-30 - 2021-12-31

#crsp_monthly_nona %>% arrange(desc(date))

```

We need the market equity (ME) at two different times, June year $t$ and December year $t-1$. We define a new column 'sorting_date' to transport them to the time when the given numbers are needed in the computation of the BE/ME underlying the Fama French HML factor.  

```{r}
# We need the me for June year t when computing the ff factor later
me_jun = crsp_monthly_nona %>% 
  filter(month(month) == 6) %>% 
  mutate(sorting_date = month %m+% months(1)) %>% 
  select(permno, sorting_date, me_j = mktcap)

# December year t-1
me_dec = crsp_monthly_nona %>% 
  filter(month(month) == 12) %>% 
  mutate(sorting_date = ymd(str_c(year(month) + 1, "0701"))) %>% 
  select(permno, gvkey, sorting_date, bm_me = mktcap) 

```


We merge CRSP and Compustat, seperately for the Moody's and Compustat. We then collect the two and compute the book-to-market (BE/ME), which underlies the Fama-French HML factor. 

```{r}
be_comp = be %>% left_join(me_dec, by = c("gvkey", "sorting_date")) %>% drop_na(bm_me, bm_be)
be_moodys = moodys %>% left_join(me_dec, by = c("permno", "sorting_date")) %>% drop_na(bm_me, bm_be)

beme_df = be_comp %>%
  full_join(be_moodys) %>% 
  mutate(beme = bm_be / bm_me) %>% 
  select(permno, sorting_date, beme) 

# beme_df %>% arrange(sorting_date) # 1927-07-01	- 2022-07-01	, 258,904 observations
```

We compute the book-to-market (BE/ME), which underlies the Fama-French HML factor. 

```{r}
# join them all together
variables = me_jun %>% 
  inner_join(beme_df, by = c("permno", "sorting_date")) %>% 
  drop_na() %>% 
  distinct(permno, sorting_date, .keep_all = TRUE)

#variables %>% arrange(sorting_date) # 1927-07-01 - 2021-07-01, 249,306 observations
```


We compute the 30 and 70 percent quantiles and compares with the true Fama French breakpoints. We remember that the Fama French breakpoints are computed using NYSE only. We therefore merge with the CRSP data to be able to filter on exchange

```{r}
bm_percentiles = variables %>% 
  inner_join(crsp_monthly_nona, by = c("permno" = "permno", "sorting_date" = "month")) %>% # inner join to make sure we only consider stocks traded
  group_by(sorting_date) %>% 
  filter(exchange == "NYSE") %>% 
  summarize(breakpoint_30 = quantile(beme, 0.3),
            breakpoint_70 = quantile(beme, 0.7)) 

bm_percentiles_melt = melt(bm_percentiles, id.vars = "sorting_date") %>% mutate(date = as.numeric(year(sorting_date))) %>% select(-sorting_date)

bm_percentiles_melt %>% 
  ggplot() +
  aes(x=date, y=value, color=variable) +
  geom_line(aes(linetype=variable), linewidth=1) +
  scale_x_continuous(limits = c(1960, 2020)) + 
  scale_y_continuous(limits=c(0,3)) +
  theme_bw() 

# plot with the true breakpoints 
FF_beme_true_raw <- download_french_data("BE/ME Breakpoints") 
FF_beme_true <- FF_beme_true_raw$subsets$data[[1]] %>% 
  rename(all_percentiles ='>0') %>% 
  mutate(percentiles_aslist = as.list(strsplit(all_percentiles, ",")))

lower = sapply(FF_beme_true$percentiles_aslist, `[[`, 7) %>% str_replace_all("\\s+", "") %>% as.numeric()
upper = sapply(FF_beme_true$percentiles_aslist, `[[`, 15) %>% str_replace_all("\\s+", "") %>% as.numeric()

ff_true_df = data.frame(date = FF_beme_true$date, FF_breakpoint_30=lower, FF_breakpoint_70=upper) %>% melt(id.vars = "date") 

full_df = ff_true_df %>% full_join(bm_percentiles_melt)

full_df %>% 
  mutate(variable = gsub("FF_breakpoint_30", "Fama-French 30%", variable),
         variable = gsub("FF_breakpoint_70", "Fama-French 70%", variable),
         variable = gsub("breakpoint_30", "Replicated 30%", variable),
         variable = gsub("breakpoint_70", "Replicated 70%", variable)) %>% 
  ggplot() +
  aes(x=date, y=value, color=variable) +
  geom_line(aes(linetype=variable), linewidth=1) +
  scale_x_continuous(limits = c(1926, 2020), name = "Date") + 
  scale_y_continuous(name = "Book-to-Market") +
  theme_bw() +
  scale_color_brewer(palette = "Set1") +
  labs(color = NULL, linetype = NULL) +
  theme(legend.position = c(.8, .8))
ggsave("Ex2Problem1.png")
```


 
## Problem 2 
Create a data set of monthly return data, describe your approach. Compute the standard deviation of returns each month, and plot the resulting series over time. 

In problem 1 we used stock data from CRSP. We will use the same stock data here. We use the same stock exchanges, which are used to construct the Fama-French portfolios. 

```{r}
crsp_monthly_nona_ret = crsp_monthly_nona %>% drop_na(ret)

crsp_monthly_nona_ret %>% 
  #filter(exchange != "Other") %>% 
  group_by(month, exchange) %>% 
  summarise(std_dev_ret = sd(ret)) %>% 
  ggplot() +
  aes(x=month, y=std_dev_ret, color = exchange) +
  geom_line() +
  theme_bw() +
   theme(legend.position = c(.1, .8)) +
  labs(y = "Standard Deviation", x = "Date", color="Exchange")
ggsave("sd_exchanges.png")

crsp_monthly_nona_ret %>% 
  filter(exchange != "Other") %>% 
  group_by(month, exchange) %>% 
  summarise(std_dev_ret = sd(ret)) %>% 
  ggplot() +
  aes(x=month, y=std_dev_ret, color = exchange) +
  geom_line() +
  theme_bw() +
   theme(legend.position = c(.1, .8)) +
  labs(y = "Standard Deviation", x = "Date", color="Exchange")
ggsave("sd_exchanges_other.png")

# all exchanges 
crsp_monthly_nona_ret %>% 
  #filter(exchange != "Other") %>% 
  group_by(month) %>% 
  summarise(std_dev_ret = sd(ret)) %>% 
  ggplot() +
  aes(x=month, y=std_dev_ret) +
  geom_line() +
  theme_bw() +
  labs(y = "Standard Deviation", x = "Date", color="Exchange")
ggsave("sd_exchanges_all.png")
```


## Problem 3
Combining the characteristic data and the return data, create a monthly return series of the HML factor in the US. Describe your approach, plot the cumulative return of your factor alongside HMLFF, and report the Pearson correlation between the monthly returns of the two factors. 

We start by creating a function to help us create the six portfolios. This function takes in the sorting variable and the quantiles and returns the data values in the wanted 'buckets'. The function returns an identification number for which 'bucket' a given pair of (permno, date) belongs to. 

```{r}
# Construct the data set to be used for portfolio constructing (this is pretty much done already we just need to merge)
crsp_monthly_nona_hml = crsp_monthly_nona %>% select(
  permno, month, ret_excess, exchange, mktcap_lag
) %>% 
  drop_na()

ff_replication_data = variables %>% # 248,899
  inner_join(crsp_monthly_nona_hml, # Use inner_join with the computed return data set, so we only use traded stocks when computing the breakpoints
             by = c("permno" = "permno", "sorting_date" = "month")) # 247,233 
#filter(sorting_date >= as.Date("1957-07-01"))

portfolio_sort <- function(data, variable, percentiles) {
  breakpoints <- data %>% 
    filter(exchange == "NYSE") %>%  # remember that FF use NYSE only for breakpoints
    drop_na() %>% 
    summarize(breakpoint = quantile(
      {{ variable }}, 
      # potentially write substitute or deparse(subsitute(variable)) instead
      # it's due to how R evaluates function calls and input variables
      probs = {{ percentiles }},
      na.rm = TRUE
    )) %>% 
    pull(breakpoint) %>% 
    as.numeric()

  sorted_portfolios <- data %>% 
    drop_na() %>% 
    mutate(portfolio = findInterval({{ variable }},
      breakpoints,
      all.inside = TRUE
    )) %>% 
    pull(portfolio)

  return(sorted_portfolios)
}

# Construct the six portfolios
portfolios_hml = ff_replication_data %>% 
  group_by(sorting_date) %>% 
  mutate(
    # sort on size (market equity)
    portfolio_me = portfolio_sort(data = cur_data(), variable = me_j, percentiles = c(0, 0.5, 1)), # returns a column with 1 or 2
    # sort on value (book-to-market)
    portfolio_beme = portfolio_sort(data = cur_data(), variable = beme, percentiles = c(0, 0.3, 0.7, 1))) %>%  # returns a column of 1, 2 or 3
  select(permno, sorting_date, portfolio_me, portfolio_beme) # returns a data frame with (permno, sorting_date) pairs and the corresponding size and value 'bucket'

```

We add the newly created portfolios to the return data. Before we can do this we need to adapt the return data to the portfolio data. Remember we use the column sorting_date to compare when we update our portfolio, which is done in June of year t. So we set months which are June or before, to the previous pf holding period (i.e. move them to July t-1) and set the remaining months to July year t.

```{r}
portfolios_hml <- crsp_monthly_nona_hml %>% 
  mutate(sorting_date = case_when(
    month(month) <= 6 ~ ymd(str_c(year(month) - 1, "0701")),
    month(month) >= 7 ~ ymd(str_c(year(month), "0701"))
  )) %>% 
  inner_join(portfolios_hml, by = c("permno", "sorting_date"))
```



```{r}
hml_monthly_replicated <- portfolios_hml %>% 
  mutate(portfolio = str_c(portfolio_me, portfolio_beme)) %>% # create one identification number instead of two
  group_by(portfolio, month) %>% 
  summarize(
    ret = weighted.mean(ret_excess, mktcap_lag), .groups = "drop", # compute the value weighted average
    portfolio_me = unique(portfolio_me),
    portfolio_beme = unique(portfolio_beme)
  ) %>% 
  group_by(month) %>% 
  summarize(
    hml_replicated = mean(ret[portfolio_beme == 3]) - # 1/2(Small Value + Big Value)
      mean(ret[portfolio_beme == 1])                  # 1/2(Small Growth + Big Growth)
  )
```


We plot the cumulative return of our replicated factor alongside the Fama-French HML factor.
```{r}
hml_factors = ff_monthly %>% 
  inner_join(hml_monthly_replicated, by = "month") %>% 
  select(month, hml, replicated = hml_replicated) 

# compute pearson correlation 
(correlation <- cor(hml_factors$hml, hml_factors$replicated, method = 'pearson'))

hml_factors %>% 
  mutate(hml = cumsum(hml),
         replicated = cumsum(replicated)) %>% 
  melt(id.vars = "month") %>% 
  mutate(variable = gsub("hml", "Fama-French HML", variable),
         variable = gsub("replicated", "HML replicated", variable)) %>% 
  ggplot() +
  aes(x=month, y=value, color=variable) +
  geom_line(aes(linetype=variable), linewidth=1, alpha=0.7) +
  theme_bw() +
  scale_color_brewer(palette = "Set1") +
  labs(color = NULL, linetype = NULL, x = "Date", y = "Cumulative HML factor return ($)") +
  annotate("text", x = as.Date("1960-10-01"), y=2.5, label= paste("Pearson correlation:\n", round(correlation,5))) +
   theme(legend.position = c(.8, .2)) +
  scale_x_date(breaks = date_breaks("5 years"), labels = date_format("%Y"))
ggsave("Ex2Problem3moody.png")

```


## Problem 4
Compare and contrast the HML factor you have created with the US Book-to-Market equity factor from JKPfactors.com (both the equal-weighted, value-weighted, capped-value-weighted).

```{r}
library(readr)
X_usa_be_me_monthly_vw_cap <- read_csv("[usa]_[be_me]_[monthly]_[vw_cap].csv") %>% mutate(month = floor_date(date, "month")) %>% rename(cap = ret) %>% select(cap, month)
X_usa_be_me_monthly_vw     <- read_csv("[usa]_[be_me]_[monthly]_[vw].csv") %>% mutate(month = floor_date(date, "month")) %>% rename(vw = ret) %>% select(vw, month)
X_usa_be_me_monthly_ew     <- read_csv("[usa]_[be_me]_[monthly]_[ew].csv") %>% mutate(month = floor_date(date, "month")) %>% rename(ew = ret) %>% select(ew, month)

jkp_beme = X_usa_be_me_monthly_vw_cap %>% inner_join(X_usa_be_me_monthly_vw) %>% inner_join(X_usa_be_me_monthly_ew)

all_hml = jkp_beme %>% inner_join(hml_factors) 

all_hml %>% 
  melt(id.vars = "month") %>% 
  group_by(variable) %>% 
  mutate(value = cumsum(value),
         variable = gsub("hml", "Fama-French HML", variable),
         variable = gsub("replicated", "HML replicated", variable),
         variable = gsub("ew", "Equal-weighted JKP", variable),
         variable = gsub("vw", "Value-weighted JKP", variable),
         variable = gsub("cap", "Value-weighted w. cap JKP", variable)) %>% 
  ggplot() +
  aes(x=month, y=value, color=variable) +
  geom_line(aes(linetype=variable), linewidth=1, alpha=0.4) +
  theme_bw() +
  scale_color_brewer(palette = "Set1") +
  labs(color = NULL, linetype = NULL, x = "Date", y = "Cumulative factor return ($)")  +
  theme(legend.position = c(.2, .8))

ggsave("Ex2Problem4.png")
# print correlation matrix
cor(all_hml %>% select(-month), method = "pearson")

# check correlation with fama-french hml only
apply(all_hml %>% select(-month), 2, cor, x = all_hml$hml)
```

